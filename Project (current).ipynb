{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A whole lot of imports\n",
    "import rasterio\n",
    "import rasterio.transform\n",
    "import rasterio.mask\n",
    "import fiona\n",
    "import shapely\n",
    "import shapely.geometry\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "import pyproj\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import mpl_toolkits.basemap as pbm\n",
    "\n",
    "import rasterio.features\n",
    "import rasterio.windows\n",
    "from rasterio.windows import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw code for masking a raster using the rasterio.mask.mask() function\n",
    "# No longer part of rasterio package so should just be called by mask()\n",
    "# Added feature where parameter out_dtype can be set\n",
    "# and is fed into the out_dtype parameter of the read() function for reading a file\n",
    "\n",
    "\n",
    "\"\"\"Mask the area outside of the input shapes with no data.\"\"\"\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from rasterio.errors import WindowError\n",
    "from rasterio.features import geometry_mask, geometry_window\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def raster_geometry_mask(dataset, shapes, all_touched=False, invert=False,\n",
    "                         crop=False, pad=False, pad_width=0.5):\n",
    "    \"\"\"Create a mask from shapes, transform, and optional window within original\n",
    "    raster.\n",
    "    By default, mask is intended for use as a numpy mask, where pixels that\n",
    "    overlap shapes are False.\n",
    "    If shapes do not overlap the raster and crop=True, a ValueError is\n",
    "    raised.  Otherwise, a warning is raised, and a completely True mask\n",
    "    is returned (if invert is False).\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : a dataset object opened in 'r' mode\n",
    "        Raster for which the mask will be created.\n",
    "    shapes : iterable object\n",
    "        The values must be a GeoJSON-like dict or an object that implements\n",
    "        the Python geo interface protocol (such as a Shapely Polygon).\n",
    "    all_touched : bool (opt)\n",
    "        Include a pixel in the mask if it touches any of the shapes.\n",
    "        If False (default), include a pixel only if its center is within one of\n",
    "        the shapes, or if it is selected by Bresenham's line algorithm.\n",
    "    invert : bool (opt)\n",
    "        If False (default), mask will be `False` inside shapes and `True`\n",
    "        outside.  If True, mask will be `True` inside shapes and `False`\n",
    "        outside.\n",
    "    crop : bool (opt)\n",
    "        Whether to crop the dataset to the extent of the shapes. Defaults to\n",
    "        False.\n",
    "    pad : bool (opt)\n",
    "        If True, the features will be padded in each direction by\n",
    "        one half of a pixel prior to cropping dataset. Defaults to False.\n",
    "    pad_width : float (opt)\n",
    "        If pad is set (to maintain back-compatibility), then this will be the\n",
    "        pixel-size width of the padding around the mask.\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Three elements:\n",
    "            mask : numpy ndarray of type 'bool'\n",
    "                Mask that is `True` outside shapes, and `False` within shapes.\n",
    "            out_transform : affine.Affine()\n",
    "                Information for mapping pixel coordinates in `masked` to another\n",
    "                coordinate system.\n",
    "            window: rasterio.windows.Window instance\n",
    "                Window within original raster covered by shapes.  None if crop\n",
    "                is False.\n",
    "    \"\"\"\n",
    "    if crop and invert:\n",
    "        raise ValueError(\"crop and invert cannot both be True.\")\n",
    "\n",
    "    if crop and pad:\n",
    "        pad_x = pad_width\n",
    "        pad_y = pad_width\n",
    "    else:\n",
    "        pad_x = 0\n",
    "        pad_y = 0\n",
    "\n",
    "    north_up = dataset.transform.e <= 0\n",
    "    rotated = dataset.transform.b != 0 or dataset.transform.d != 0\n",
    "\n",
    "    try:\n",
    "        window = geometry_window(dataset, shapes, north_up=north_up, rotated=rotated,\n",
    "                                 pad_x=pad_x, pad_y=pad_y)\n",
    "\n",
    "    except WindowError:\n",
    "        # If shapes do not overlap raster, raise Exception or UserWarning\n",
    "        # depending on value of crop\n",
    "        if crop:\n",
    "            raise ValueError('Input shapes do not overlap raster.')\n",
    "        else:\n",
    "            warnings.warn('shapes are outside bounds of raster. '\n",
    "                          'Are they in different coordinate reference systems?')\n",
    "\n",
    "        # Return an entirely True mask (if invert is False)\n",
    "        mask = np.ones(shape=dataset.shape[-2:], dtype='bool') * (not invert)\n",
    "        return mask, dataset.transform, None\n",
    "\n",
    "    if crop:\n",
    "        transform = dataset.window_transform(window)\n",
    "        out_shape = (int(window.height), int(window.width))\n",
    "\n",
    "    else:\n",
    "        window = None\n",
    "        transform = dataset.transform\n",
    "        out_shape = (int(dataset.height), int(dataset.width))\n",
    "\n",
    "    mask = geometry_mask(shapes, transform=transform, invert=invert,\n",
    "                         out_shape=out_shape, all_touched=all_touched)\n",
    "\n",
    "    return mask, transform, window\n",
    "\n",
    "\n",
    "def mask(dataset, shapes, all_touched=False, invert=False, nodata=None,\n",
    "         filled=True, crop=False, pad=False, pad_width=0.5, indexes=None, out_dtype = None):\n",
    "    \"\"\"Creates a masked or filled array using input shapes.\n",
    "    Pixels are masked or set to nodata outside the input shapes, unless\n",
    "    `invert` is `True`.\n",
    "    If shapes do not overlap the raster and crop=True, a ValueError is\n",
    "    raised.  Otherwise, a warning is raised.\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : a dataset object opened in 'r' mode\n",
    "        Raster to which the mask will be applied.\n",
    "    shapes : iterable object\n",
    "        The values must be a GeoJSON-like dict or an object that implements\n",
    "        the Python geo interface protocol (such as a Shapely Polygon).\n",
    "    all_touched : bool (opt)\n",
    "        Include a pixel in the mask if it touches any of the shapes.\n",
    "        If False (default), include a pixel only if its center is within one of\n",
    "        the shapes, or if it is selected by Bresenham's line algorithm.\n",
    "    invert : bool (opt)\n",
    "        If False (default) pixels outside shapes will be masked.  If True,\n",
    "        pixels inside shape will be masked.\n",
    "    nodata : int or float (opt)\n",
    "        Value representing nodata within each raster band. If not set,\n",
    "        defaults to the nodata value for the input raster. If there is no\n",
    "        set nodata value for the raster, it defaults to 0.\n",
    "    filled : bool (opt)\n",
    "        If True, the pixels outside the features will be set to nodata.\n",
    "        If False, the output array will contain the original pixel data,\n",
    "        and only the mask will be based on shapes.  Defaults to True.\n",
    "    crop : bool (opt)\n",
    "        Whether to crop the raster to the extent of the shapes. Defaults to\n",
    "        False.\n",
    "    pad : bool (opt)\n",
    "        If True, the features will be padded in each direction by\n",
    "        one half of a pixel prior to cropping raster. Defaults to False.\n",
    "    indexes : list of ints or a single int (opt)\n",
    "        If `indexes` is a list, the result is a 3D array, but is\n",
    "        a 2D array if it is a band index number.\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Two elements:\n",
    "            masked : numpy ndarray or numpy.ma.MaskedArray\n",
    "                Data contained in the raster after applying the mask. If\n",
    "                `filled` is `True` and `invert` is `False`, the return will be\n",
    "                an array where pixels outside shapes are set to the nodata value\n",
    "                (or nodata inside shapes if `invert` is `True`).\n",
    "                If `filled` is `False`, the return will be a MaskedArray in\n",
    "                which pixels outside shapes are `True` (or `False` if `invert`\n",
    "                is `True`).\n",
    "            out_transform : affine.Affine()\n",
    "                Information for mapping pixel coordinates in `masked` to another\n",
    "                coordinate system.\n",
    "    \"\"\"\n",
    "\n",
    "    if nodata is None:\n",
    "        if dataset.nodata is not None:\n",
    "            nodata = dataset.nodata\n",
    "        else:\n",
    "            nodata = 0\n",
    "\n",
    "    shape_mask, transform, window = raster_geometry_mask(\n",
    "        dataset, shapes, all_touched=all_touched, invert=invert, crop=crop,\n",
    "        pad=pad, pad_width=pad_width)\n",
    "\n",
    "    if indexes is None:\n",
    "        out_shape = (dataset.count, ) + shape_mask.shape\n",
    "    elif isinstance(indexes, int):\n",
    "        out_shape = shape_mask.shape\n",
    "    else:\n",
    "        out_shape = (len(indexes), ) + shape_mask.shape\n",
    "\n",
    "    out_image = dataset.read(\n",
    "        window=window, out_shape=out_shape, masked=True, indexes=indexes, out_dtype = out_dtype)\n",
    "\n",
    "    out_image.mask = out_image.mask | shape_mask\n",
    "\n",
    "    if filled:\n",
    "        out_image = out_image.filled(nodata)\n",
    "\n",
    "    return out_image, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to warp from one coordinate system to another\n",
    "# warping crs\n",
    "def warp_xy(x, y, old_crs, new_crs):\n",
    "    \"\"\"Warps a set of points from old_crs to new_crs.\"\"\"\n",
    "    if old_crs == new_crs:\n",
    "        return x,y\n",
    "\n",
    "    old_crs_proj = pyproj.Proj(old_crs)\n",
    "    new_crs_proj = pyproj.Proj(new_crs)\n",
    "    return pyproj.transform(old_crs_proj, new_crs_proj, x,y)\n",
    "\n",
    "def warp_shapely(shp, old_crs, new_crs):\n",
    "    \"\"\"Uses proj to reproject shapes, NOT IN PLACE\"\"\"\n",
    "    if old_crs['init'] == new_crs['init']:\n",
    "        return shp\n",
    "\n",
    "    old_crs_proj = pyproj.Proj(old_crs)\n",
    "    new_crs_proj = pyproj.Proj(new_crs)\n",
    "    return shapely.ops.transform(lambda x,y:pyproj.transform(old_crs_proj, new_crs_proj, x,y), shp)\n",
    "\n",
    "def warp_shape(feature, old_crs, new_crs):\n",
    "    \"\"\"Uses proj to reproject shapes, IN PLACE\"\"\"\n",
    "    if old_crs == new_crs:\n",
    "        return\n",
    "    if len(feature['geometry']['coordinates']) is 0:\n",
    "        return\n",
    "\n",
    "    # find the dimension -- can't trust the shape\n",
    "    dim = -1\n",
    "    ptr = feature['geometry']['coordinates']\n",
    "    done = False\n",
    "    while not done:\n",
    "        if hasattr(ptr, '__len__'):        \n",
    "            assert(len(ptr) is not 0)\n",
    "            dim += 1\n",
    "            ptr = ptr[0]\n",
    "        else:\n",
    "            done = True\n",
    "\n",
    "    if dim == 0:\n",
    "        # point\n",
    "        x,y = warp_xy(np.array([feature['geometry']['coordinates'][0],]), np.array([feature['geometry']['coordinates'][1],]), old_crs, new_crs)\n",
    "        feature['geometry']['coordinates'][0] = x[0]\n",
    "        feature['geometry']['coordinates'][1] = x[1]\n",
    "    elif dim == 1:\n",
    "        # line-like or polygon with no holes\n",
    "        coords = np.array(feature['geometry']['coordinates'],'d')\n",
    "        assert(len(coords.shape) is 2 and coords.shape[1] in [2,3] )\n",
    "        x,y = warp_xy(coords[:,0], coords[:,1], old_crs, new_crs)\n",
    "        new_coords = [xy for xy in zip(x,y)]\n",
    "        feature['geometry']['coordinates'] = new_coords\n",
    "    elif dim == 2:\n",
    "        # multi-line or polygon with holes\n",
    "        for i in range(len(feature['geometry']['coordinates'])):\n",
    "            coords = np.array(feature['geometry']['coordinates'][i],'d')\n",
    "            assert(len(coords.shape) is 2 and coords.shape[1] in [2,3])\n",
    "            x,y = warp_xy(coords[:,0], coords[:,1], old_crs, new_crs)\n",
    "            new_coords = [xy for xy in zip(x,y)]\n",
    "            feature['geometry']['coordinates'][i] = new_coords\n",
    "    elif dim == 3:\n",
    "        # multi-polygon\n",
    "        for i in range(len(feature['geometry']['coordinates'])):\n",
    "            for j in range(len(feature['geometry']['coordinates'][i])):\n",
    "                coords = np.array(feature['geometry']['coordinates'][i][j],'d')\n",
    "                assert(len(coords.shape) is 2 and coords.shape[1] in [2,3])\n",
    "                x,y = warp_xy(coords[:,0], coords[:,1], old_crs, new_crs)\n",
    "                new_coords = [xy for xy in zip(x,y)]\n",
    "                feature['geometry']['coordinates'][i][j] = new_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the data that we will be using\n",
    "\n",
    "def filter_msas(cbsas):\n",
    "    # Finds which cbsas are major and classify as MSAs\n",
    "    # Also omits msas from Puerto Rico, Hawaii, and Alaska\n",
    "    # msas is a list that contains the shapes for each MSA in the lower 48 states\n",
    "    msas = []\n",
    "    for cbsa in cbsas:\n",
    "        cbsa_type = cbsa['properties']['LSAD']\n",
    "        if cbsa_type == 'M1':\n",
    "            if 'PR' not in cbsa['properties']['NAME'] and 'HI' not in cbsa['properties']['NAME'] and 'AK' not in cbsa['properties']['NAME']:\n",
    "                msas.append(cbsa)\n",
    "    return msas\n",
    "\n",
    "def filter_test(cbsas):\n",
    "    msas = filter_msas(cbsas)\n",
    "    tests = msas[0:7]+[msas[13], msas[31], msas[121]]\n",
    "    return tests\n",
    "\n",
    "def filter_first_100(cbsas):\n",
    "    msas = filter_msas(cbsas)\n",
    "    tests = msas[0:100]\n",
    "    return tests\n",
    "\n",
    "def filter_name(cbsas):\n",
    "    msas = filter_msas(cbsas)\n",
    "    name = input()\n",
    "    name_msas = [msa for msa in msas if name in msa['properties']['NAME']]\n",
    "    assert(len(name_msas) == 1)\n",
    "    return name_msas\n",
    "\n",
    "# import and potentially warp all U.S. CBSA shapes\n",
    "def load_cbsas(file=r'..\\Data (Used)\\tl_2017_us_cbsa\\tl_2017_us_cbsa.shp', crs=None, filter=None):\n",
    "    with fiona.open(file, 'r') as fid:\n",
    "        cbsas = list(fid)\n",
    "        cbsas_profile = fid.profile\n",
    "    #print(\"We found {} CBSA shapes\".format(len(cbsas)))\n",
    "    #print('What CRS are we working in?')\n",
    "    #print('  crs of CBSAs:', cbsas_profile['crs'])\n",
    "    if filter is not None:\n",
    "        cbsas = filter(cbsas)\n",
    "    \n",
    "    if crs is not None:\n",
    "        for shp in cbsas:\n",
    "            warp_shape(shp, cbsas_profile['crs'], crs) \n",
    "    cbsas_profile['crs'] = crs\n",
    "    return cbsas, cbsas_profile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_on_msa(msa_shapely, path):\n",
    "    \"\"\"Takes in an MSA and data raster and returns a box of the data from the raster\"\"\"\n",
    "    with rasterio.open(path) as fid:\n",
    "        transform = fid.profile['transform']\n",
    "        msa_bounds = msa_shapely.bounds\n",
    "        ll = msa_bounds[0], msa_bounds[1]\n",
    "        ur = msa_bounds[2], msa_bounds[3]\n",
    "        ij_ll = tuple(reversed(rasterio.transform.rowcol(transform, *ll)))\n",
    "        ij_ur = tuple(reversed(rasterio.transform.rowcol(transform, *ur)))\n",
    "        boxed_msa = fid.read(1, window = ((ij_ur[1], ij_ll[1]), (ij_ll[0], ij_ur[0])))\n",
    "    return boxed_msa, msa_bounds\n",
    "\n",
    "def mask_on_msa(msa_shapely, path):\n",
    "    \"\"\"Returns raster data masked and cropped to an MSA\"\"\"\n",
    "    with rasterio.open(path) as fid:\n",
    "        array, transform = mask(fid, [msa_shapely,], crop=True, nodata = np.nan, out_dtype = rasterio.float32)\n",
    "    return array[0,:,:], msa_shapely.bounds\n",
    "\n",
    "def get_raster_on_msa(msa, path, extent=box_on_msa):\n",
    "    \"\"\"Takes in an MSA and raster file path and plots them.\"\"\"\n",
    "    msa_shapely = shapely.geometry.shape(msa['geometry'])\n",
    "    if msa['geometry']['type'] == 'Polygon':\n",
    "        x,y = msa_shapely.exterior.xy\n",
    "        plt.plot(x,y)\n",
    "    else:\n",
    "        for poly in msa_shapely:\n",
    "            x,y = poly.exterior.xy\n",
    "            plt.plot(x,y)\n",
    "    \n",
    "    boxed_msa, msa_bounds = extent(msa_shapely, path)\n",
    "    return boxed_msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the impervious surface raster\n",
    "def get_crs(path):\n",
    "    with rasterio.open(path, 'r') as fid:\n",
    "        crs = fid.profile['crs']\n",
    "        #print(crs)\n",
    "    return crs\n",
    "\n",
    "path_imp = r'..\\Data (Used)\\NLCD_2016_Impervious_L48_20190405\\NLCD_2016_Impervious_L48_20190405.img'\n",
    "path_pop = r'..\\Data (Used)\\popdynamics-pop-projection-ssp-downscaled-1km-2010-2100-ssp2-geotiff\\SSP2_1km\\ssp2_total_2010.tif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_msa(path, msa, mask_type):\n",
    "    boxed_msa = get_raster_on_msa(msa, path, mask_type)\n",
    "    plt.imshow(boxed_msa)\n",
    "    plt.show()\n",
    "\n",
    "def load_and_plot(path, filter, mask_type):\n",
    "    crs = get_crs(path)\n",
    "    msas, profile = load_cbsas(crs=crs, filter=filter)\n",
    "    for msa in msas:\n",
    "        plot_msa(path, msa, mask_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_analyze(path, filter, mask_type):\n",
    "    crs = get_crs(path)\n",
    "    msas, profile = load_cbsas(crs=crs, filter=filter)\n",
    "    analysis_array = []\n",
    "    colnames = ['Number of pixels', 'Data Fraction', 'Summed boxed msa', 'Number of nan pixels']\n",
    "    df = pd.DataFrame(columns=colnames)\n",
    "    for msa in msas:\n",
    "        boxed_msa = get_raster_on_msa(msa, path, mask_type)\n",
    "        \"\"\"Bounds the msas data values between 0 and 1\"\"\"\n",
    "        boxed_msa_constrained = boxed_msa / 255\n",
    "        \"\"\"Adds all of the bounded data fractions within the msa\"\"\"\n",
    "        sum_boxed_msa_constrained = np.where(np.isnan(boxed_msa_constrained), 0, boxed_msa_constrained).sum()\n",
    "        \"\"\"Sums the number of nan pixels in the raster given\"\"\"\n",
    "        num_nan_pixels = np.where(np.isnan(boxed_msa_constrained), 1, 0).sum()\n",
    "        \"\"\"Find the number of pixels that lie within the msa\"\"\"\n",
    "        num_pixels = np.where(np.isnan(boxed_msa_constrained), 0, 1).sum()\n",
    "        \"\"\"Finds the average amount of data per pixel\"\"\"\n",
    "        data_fraction = sum_boxed_msa_constrained / num_pixels\n",
    "        data = [num_pixels, data_fraction, sum_boxed_msa_constrained, num_nan_pixels]\n",
    "        analysis_array.append(data)\n",
    "        df2 = pd.DataFrame([data], columns=colnames)\n",
    "        df.append(df2)  \n",
    "    \n",
    "    return df, analysis_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis_df_imp, aa_imp = load_and_analyze(path_imp, filter_test, mask_on_msa)\n",
    "analysis_df_pop, aa_pop = load_and_analyze(path_pop, filter_test, mask_on_msa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Number of pixels, Data Fraction, Summed boxed msa, Number of nan pixels]\n",
      "Index: []\n",
      "(0, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(aa_imp)\n",
    "#print(aa_pop)\n",
    "#print(analysis_df_imp)\n",
    "print(analysis_df_pop)\n",
    "\n",
    "data = [1,2,3,4]\n",
    "\n",
    "colnames = ['Number of pixels', 'Data Fraction', 'Summed boxed msa', 'Number of nan pixels']\n",
    "df2 = pd.DataFrame([data], columns=colnames)\n",
    "df3 = pd.DataFrame([data], columns=colnames)\n",
    "analysis_df_pop.append(df2)\n",
    "df2.append(df3)\n",
    "print(analysis_df_pop.shape)\n",
    "\n",
    "df = pd.DataFrame(aa_imp, columns = colnames)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of pixels</th>\n",
       "      <th>Data Fraction</th>\n",
       "      <th>Summed boxed msa</th>\n",
       "      <th>Number of nan pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number of pixels Data Fraction Summed boxed msa Number of nan pixels\n",
       "0                1             2                3                    4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Number of pixels', 'Data Fraction', 'Summed boxed msa', 'Number of nan pixels'])\n",
    "df2 = pd.DataFrame([[1,2,3,4]],columns=['Number of pixels', 'Data Fraction', 'Summed boxed msa', 'Number of nan pixels'])\n",
    "df.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mildly sketch work begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(path, filter):\n",
    "    crs = get_crs(path)\n",
    "    msas, profile = load_cbsas(crs=crs, filter=filter)\n",
    "    names = []\n",
    "    for msa in msas:\n",
    "        names.append(msa['properties']['NAME'])\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_res(filter, mask_type):\n",
    "    analysis_array_imp = load_and_analyze(path_imp, filter, mask_type)\n",
    "    analysis_array_pop = load_and_analyze(path_pop, filter, mask_type)\n",
    "    res_array = []\n",
    "    for i in range(len(msas)):\n",
    "        res_array.append(analysis_array_imp[i][0] / analysis_array_pop[i][0])\n",
    "    return res_array\n",
    "\n",
    "def data_analysis(filter, mask_type):\n",
    "    res_array = check_res(filter, mask_type)\n",
    "    filtered_res_array\n",
    "    for res in res_array:\n",
    "        if res > 700 and res < 900:\n",
    "            filtered_res_array.append()\n",
    "    plt.imshow(filtered_res_array)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analysis(filter_name, mask_on_msa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Super sketch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution_comparison = []\n",
    "for i in range(len(analysis_array_imp)):\n",
    "    print(analysis_array_imp[i][0] / analysis_array_pop[i][0])\n",
    "    resolution_comparison.append(analysis_array_imp[i][0] / analysis_array_pop[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(resolution_comparison) - 1,0,-1):\n",
    "    for i in range(j):\n",
    "        if resolution_comparison[i] > resolution_comparison[i + 1]:\n",
    "            temp = resolution_comparison[i]\n",
    "            resolution_comparison[i] = resolution_comparison[i + 1]\n",
    "            resolution_comparison[i + 1] = temp\n",
    "plt.plot(resolution_comparison)\n",
    "plt.ylabel(\"imp vs pop\")\n",
    "plt.show()\n",
    "resolution_comparison_clipped = resolution_comparison[50:300]\n",
    "plt.plot(resolution_comparison_clipped)\n",
    "plt.ylabel(\"imp vs pop clipped\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "test_imp = []\n",
    "test_pop = []\n",
    "for i in range(len(analysis_array_imp)):\n",
    "    test.append([analysis_array_imp[i][2], analysis_array_pop[i][2]])\n",
    "#sorting the data of the array\n",
    "for j in range(len(test) - 1,0,-1):\n",
    "    for i in range(j):\n",
    "        if test[i][0] > test[i + 1][0]:\n",
    "            temp = test[i][0]\n",
    "            test[i][0] = test[i + 1][0]\n",
    "            test[i + 1][0] = temp\n",
    "\n",
    "#breaks down test into smaller arrays\n",
    "for msa in test:\n",
    "    test_imp.append(msa[0])\n",
    "    test_pop.append(msa[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(test_pop, test_imp)\n",
    "plt.xlabel(\"pop frac\")\n",
    "plt.ylabel(\"imp surf frac\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum area of msas and compare to accepted values||||\n",
    "find which msas which have a imp surf to pop pixel ratio between 50 and 300 and replot||||\n",
    "add up area of each msa||||\n",
    "add up population of each msa||||\n",
    "check to see range of msa raster (maybe not 2D)||||df to csv file||||df col1 = cbsa code#, col2 = cbsa name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings:\n",
    "The number of nan pixels and normal pixels in a masked msa do not add up to the number of pixels in an unmasked msa\n",
    "Tried finding the area of msas projected for population, supposedly UTM which would mean each pixel stands for 1m^2, did not seem to line up at all with simple google search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gis)",
   "language": "python",
   "name": "gis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
